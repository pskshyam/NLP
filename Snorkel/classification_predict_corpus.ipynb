{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>D36051.pdf.out.html.txt</td>\n",
       "      <td>janet ley approval sow mcw dba dmi mobility s...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D07271.pdf.out.html.txt</td>\n",
       "      <td>agreement this schedule a this schedule is att...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>D28723.pdf.out.html.txt</td>\n",
       "      <td>wolters kluwer contingent staffing request fo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>D42247.pdf.out.html.txt</td>\n",
       "      <td>agreement received this agreement is entered i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>D19377.pdf.out.html.txt</td>\n",
       "      <td>addendum to hosting and services agreement thi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  filename                                               text  \\\n",
       "0  D36051.pdf.out.html.txt   janet ley approval sow mcw dba dmi mobility s...   \n",
       "1  D07271.pdf.out.html.txt  agreement this schedule a this schedule is att...   \n",
       "2  D28723.pdf.out.html.txt   wolters kluwer contingent staffing request fo...   \n",
       "3  D42247.pdf.out.html.txt  agreement received this agreement is entered i...   \n",
       "4  D19377.pdf.out.html.txt  addendum to hosting and services agreement thi...   \n",
       "\n",
       "   label  \n",
       "0      3  \n",
       "1      1  \n",
       "2      3  \n",
       "3      2  \n",
       "4      0  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../lstm/datafiles/train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_filtered = df_train.text.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>D00738.txt</td>\n",
       "      <td>statement of work sys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D00862.txt</td>\n",
       "      <td>statement of work m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>D03070.txt</td>\n",
       "      <td>cch incorporated   1   master consulting se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>D04125.txt</td>\n",
       "      <td>cch incorporated   14   master services agr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>D03866.txt</td>\n",
       "      <td>statement of work m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename                                               text\n",
       "0  D00738.txt                           statement of work sys...\n",
       "1  D00862.txt                             statement of work m...\n",
       "2  D03070.txt     cch incorporated   1   master consulting se...\n",
       "3  D04125.txt     cch incorporated   14   master services agr...\n",
       "4  D03866.txt                             statement of work m..."
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = pd.read_csv('linkage_files.csv')\n",
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 2)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_start_pos(text):\n",
    "    pos = 0\n",
    "    match1 = re.search(r\"(addendum|amendment|change request|change order|agreement|sow|statement of work|work order|task order)\\s+(\\S+\\s+){1,30}(by and between|by and among|between|among) (.+?) and (.+?)\", text)\n",
    "    match2 = re.search(r\"(addendum|amendment|change request|change order|agreement|sow|statement of work|work order|task order)\\s+(\\S+\\s+){1,30}(effective|dated|entered|executed|made) (.+?) and (.+?)\", text)\n",
    "    match3 = re.search(r\"(addendum|amendment|change request|change order|agreement|sow|statement of work|work order|task order)(.+?)(the undersigned)(.+?) and (.+?)\", text)\n",
    "    if match1 and match1.start() < 1000:\n",
    "        pos = match1.start()\n",
    "    elif match2 and match2.start() < 1000:\n",
    "        pos = match2.start()\n",
    "    elif match3 and match3.start() < 1000:\n",
    "        pos = match3.start()\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    #Preprocess                \n",
    "    text = text.replace('\\n',' ').lower()\n",
    "    \n",
    "    #Remove non-alpha characters\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    pos = get_text_start_pos(text)\n",
    "    text = text[pos:]\n",
    "    #Remove articles\n",
    "    #articles = ('a', 'an', 'the')\n",
    "    #text = ' '.join([t for t in text.split() if t not in articles])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['text'] = df_pred.text.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statement of work mps practice and worksteam dba s cost center between cch incorporated mphasis bfl limited december statement of work mps cch incorporated page of this statement of work sow dated december is part of the master service agreement msa executed between cch incorporated client and mphasis bfl limited consultant and is subject to the terms and conditions of the msa between client and consultant made as of january except to the extent expressly provided otherwise in this sow all the terms of the msa are incorporated by reference into this sow in the event of any inconsistent or contradictory terms between the msa and the sow the terms of the msa will control and supersede such inconsistent or contradictory terms included in the msa any terms used specifically in the sow and not otherwise defined in the msa will be defined in the sow additional terms are defined in this sow project name practice and worksteam dba s statement of work mps cch incorporated page of table of contents engagement specifics overview primary points of contact term of sow human resources security equipment software resources compensation basis fees expenses invoicing payments terms engagement deliverables milestone dates description of work and deliverables performance requirements guidelines guidelines remedies pre requisites signatures attachment system requirements statement of work mps cch incorporated page of engagement specifics overview client requires consultant resources to provide resources to work on client s pfx net suite the scope of the work will include work on sql database performance operations to include but not limited to database performance analysis recommendations for improvement participate in implementing solutions code review of the logical layer run time profiling query optimizations index optimization table partitioning profiling of cpu memory i o advance optimization replication clustering physical storage primary points of contact consultant coordinator suhasa s client relationship manager park avenue south suite new york ny office email suhasa s mphasis com client coordinator craig zdrojewski vendor relations manager cch a wolters kluwer business e douglas suite wichita ks usa office phone email craig zdrojewski wolterskluwer com term of sow this sow covers the specified period but may be modified or extended by addendum should the client require additional time or changes to existing services client can cancel the contract with a minimum of two weeks written notice sow project start date january sow project end date december in the event that the msa expires and is not renewed during the term of this sow the terms of the msa shall continue to govern this sow until this sow is completed statement of work mps cch incorporated page of human resources named consultant resources based on the execution by both parties of this sow this engagement will be scheduled and staffed by consultant as required consultant will assign to client project the resources as listed below staffing levels may be changed based upon client s business needs consultant staffing changes involving the replacement of lead or senior resources must be approved by client client may increase or decrease staffing levels not to exceed the resources listed below by providing two weeks advance notice modification of staffing levels may only occur when authorized by written or electronic notice by the client vendor relationships manager project manager business owner or vice president to consultant any such notification will be followed with an addendum to the sow consultant may only make staffing additions beyond the resources identified in this sow through an addendum to this sow resource s to be located at consultant facility in india start date january end date december manohar srinivasan lead dba start date january end date march jagadeeswaran a associate dba rajesh chinnappa j associate dba upon approval of kt from cch start date april end date december jagadeeswaran a dba rajesh chinnappa j dba resource will only be working hours per work resource will only be working hours per work availability if applicable the required client facilities and systems are available to consultant resources during normal and extended business hours unusual access to facilities and systems must be approved by client coordinator see section or other client designate roles responsibilities of consultant resources dba statement of work mps cch incorporated page of writing sql server t sql specifically data definition language ddl in creating and altering database objects such as tables indexes constraints etc ability to use an editor to create and modify sql scripts containing t sql ability to run and test sql scripts and analyze results supporting development and test sql server databases analyzing database requirements for batch reporting and analysis applications reviewing and approving application based scripts utilities stored procedures functions and triggers providing general database expertise to application projects assuring security of database environment providing on call support for database problems and off hour s maintenance providing query performance monitoring and tuning recommendations installing and maintaining sqlserver performance database data loading and backups and recovery database performance tuning other duties as assigned lead dba coordination of tasks to associate dbas along with completing tasks that may be assigned to them writing sql server t sql specifically data definition language ddl in creating and altering database objects such as tables indexes constraints etc ability to use an editor to create and modify sql scripts containing t sql ability to run and test sql scripts and analyze results supporting development and test sql server databases analyzing database requirements for batch reporting and analysis applications reviewing and approving application based scripts utilities stored procedures functions and triggers providing general database expertise to application projects assuring security of database environment providing on call support for database problems and off hour s maintenance providing query performance monitoring and tuning recommendations installing and maintaining sqlserver performance database data loading and backups and recovery database performance tuning other duties as assigned general requirements human resources by accepting this sow consultant hereby warrants and represents that all personnel hired to provide services defined in this agreement have been advised of all provisions of the msa regarding consultants and have signed confidentiality agreements and have agreed to be bound by them statement of work mps cch incorporated page of if applicable all visa and permit issues must be handled prior to the start date of the assignment and consultant must ensure all necessary documentation is in order for all on site resources to legally reside and work in the united states consultant will keep visa and permits current for all named consultant resources consultant resources will be available to travel to client s us location upon reasonable request by client resources as designated in section will be dedicated to client projects outlined in this sow for the duration of this sow consultant cannot subcontract or outsource client work without prior written approval of the client or as otherwise stipulated in the msa consultant will provide a list of approved work holidays for india to client for project tasks on a critical path of completion consultant will be expected to provide additional work time before or immediately after a designated holiday to keep project on schedule for all stakeholders consultant will provide client a list of scheduled and unscheduled work absences for all assigned consultant resources consultant agrees to not invoice nor will client pay invoicing for any scheduled or unscheduled work absences consultant agrees to provide client a minimum of days advanced notice for all scheduled absences consultant agrees to communicate any unscheduled absences to designated client management immediately consultant will be available for a weekly meeting to determine status and future direction of the project during normal client business hours client will direct and monitor the consultant s on site and or off site resources including time spent on the project all on site and or off site personnel are expected to arrive for work on time and adhere to the conduct guidelines generally applied to the client s full time personnel consultant personnel must produce results that are of sufficient quality to be accepted by the client consultant will not disengage resources deployed for client during this sow unless the following conditions apply employee leaves consultant upon resigning from consultant organization employees in consultant organization are required to provide at least days notice consultant will implement a comprehensive transition during this period at consultant s own cost client asks for a replacement for performance reasons this will be carried out by consultant based upon reasonable notice by client replacement of consultant staff for performance reasons this will be carried out by consultant and communicated to client consultant will provide details of performance issues causing replacement at client s request statement of work mps cch incorporated page of employee has worked on this engagement for months or more and would like an alternate assignment in such a situation consultant will discuss this with client and arrive at a suitable transition plan the employee could be retained for the client sow in a different role or transitioned out of the sow in a planned manner consultant will assume all costs associated with the replacement of the required resource client retains the right to interview and approve potential replacement personnel consultant agrees to notify designated client management within hours of notification of any turnover in assigned consultant resources security upon security approval from client all consultant resources including shadow designees are required to have either a client provided lotus notes or team foundation user id as applicable per project for the purpose of reporting defects under no circumstance shall consultant be permitted to share or transfer client user ids consultant accepts responsibility to immediately notify client of resources exiting this sow for the purpose of deactivating user ids consultant must take appropriate security measures to prevent unauthorized use of user ids by changing the password assigned to the user id being deactivated by client during the time period of notifying client and client completing the deactivation process on site and off site consultant resources will comply with client s existing security policies off site resources will use vpn connectivity to access client network resources and machinery o remote access users must use the access granted only for the purposes authorized o remote access users must not leave their computer unattended when remotely connected to client resources o remote access users must not disclose non public confidential or proprietary information gained through remote access without obtaining permission from client o remote access users must report to client all situations where consultant believes any information breach security vulnerability or violation may exist o remote access users should have the latest anti virus signature file applied prior to connecting to any client network resources o remote access users should have a personal or corporate firewall protection prior to remotely connecting to any client network resources equipment software resources client will provide to offsite consultant resources the needed connectivity and the resources necessary to accomplish the business goals specified in this sow client will provide to onsite consultant resources the workspace computer supplies and necessary software required to accomplish the business goals as specified in this sow statement of work mps cch incorporated page of consultant will provide to offsite consultant the workspace computer supplies and infrastructure resources required to accomplish the business goals of and meet the requirements detailed in this sow hardware must meet the minimum hardware and software requirements as defined in attachment system requirements consultant must mandate that all pcs are running symantec corporate anti virus or comparable protection software consultant must keep all client provided software installed at off site locations updated with the most current versions available and in use by the client all software installed on consultant hardware which is provided by client for this sow is for use exclusively with this project and remains the licensed property of the client upon completion or termination of this engagement consultant must remove all client software from consultant hardware consultant may not transfer or use client software resources for any non approved project or activity no unauthorized software shall be installed or used on any client hardware resource or computer network without prior written approval by the client compensation basis the following conditions apply to this sow for the duration of the contract unless specifically designated otherwise compensation specific to this agreement may be modified at client s discretion by addendum to this sow fees expenses compensation the following compensation structure applies to this sow time and expenses for the purpose of this sow client agrees to the rates and hours specified below if applicable hours in excess of the budgeted weekly limits must be approved in advance by the client project manager or business owner fixed fee the project will be executed on fixed price the following table provides the payment break up consultant will guarantee the following rates for the duration of this sow offshore associate dba usd hour dba usd hour lead dba usd hour statement of work mps cch incorporated page of incidentals the following applies for the duration of this sow pre approved travel expense incidentals to be covered by client travel expense incidentals covered by consultant none client will cover up to usd airfare per person for the resource s specified airfare must reflect the lowest cost of no less than three independent prices quotations for air transportation all bookings must be coach class and purchased no less than three weeks in advance of departure unless otherwise approved in advance by client client will not pay for long distance or international calls business calls must be pre approved by the client manager and occur from the wichita kansas facility as required budget the total maximum fees incurred under this sow as outlined in the attached schedules a b b shall not exceed usd in compensation and no incidentals exceptions consultant will provide resource s in excess of hours per week without charge including weekends to client when required to complete the deliverables in this sow and where the requirements are similar to work performed by client resources client agrees to limit non payment overtime to no more than of regular hours worked within this sow invoicing all fees and expenses are payable in us dollars consultant will invoice client and client will pay consultant at the rates and times specified in this sow billing inquires should be directed to cch incorporated attn financial controller s office east douglas suite wichita ks usa phone email tc wichitacontroller wolterskluwer com consultant will invoice client every days for the work performed in the period designated by this sow all rates in this sow shall be exclusive of any applicable taxes consultant will invoice client using an itemized method by specifying within the invoice each engaged resource total hours spent on project for the duration of invoicing period per resource and associated billing totals payments terms payment will be made within days of invoicing by wire transfer statement of work mps cch incorporated page of engagement deliverables milestone dates description of work and deliverables resource s will perform the following services key contributor in the design development and implementation of proprietary pfx practice workstream reports products primary technical focus is the improvements related to t sql implementations that support the development of business logic code and ui performance optimization using latest net technology deliverables include feature sets identified by management for production release of pfx net application sql server performance tuning reports sql alter scripts for each development build exit criteria code developed by consultant is reviewed by architect and team lead and no more refactoring is needed technical design documents are signed off defect coverage meets the team s agreed upon standards no p or p bugs for assigned areas deliverables for invoicing consultant s are required to complete before invoicing a work item must be created in designated tracking system within business day detailing the work performed for each resource on the previous business day a the work item will contain the resource name project id work item type and hours a detailed resource matrix should be provided with the monthly invoice the resource matrix will consist of the resource name project id task id and hours example below this information will be used for key performance indicator tracking and portfolio management resource name project task hours smith bob scan research smith bob scan new dev smith bob scan defects smith bob pdflyer architecture smith bob pdflyer poc smith bob pdflyer unit tests rally user stories must be updated with task items and estimates before the sprint begins iterations planning meeting will define what stories are being worked on for the current iteration cycle statement of work mps cch incorporated page of each resource must plan out what they are going to work on for the integration with the given velocity of hours offshore team will relay any impediments they have that need to be resolved to the onshore contact associated with that team via email meetings will be called as needed weekly meetings will occur to review all tasks worked on by team members along with review of impediments raised during the week and review of the steps made to close the impediments performance requirements guidelines guidelines consultant resources will be expected to perform their assigned tasks as directed by client and as defined in section remedies if any of the consultant resources do not start on the designated start date which consultant had previously agreed a credit will be applied to the client for each day of absence up to a maximum period of two months if any consultant is unable to maintain the responsibility for the work assigned off site consultant assumes costs for the training of replacement resources if any consultant resource becomes unable to perform the duties required by this sow for any reason consultant may be held responsible for all costs associated with obtaining replacement personnel necessary to complete the work outlined in the sow and according to the original timing pre requisites client will be responsible for providing all consultant resources with sufficient product access and specifications and for making sufficient resources available to appropriately describe the project definition and scope to consultant in a timely manner if any of these conditions are not completed prior to the start of this agreement the client agrees not to withhold payment from consultant for hours at the client site awaiting the completion of these pre requisites by the client it is client s responsibility to specify a business owner and client project manager prior to the start of this assignment the consultant will work with the client project manager and report to the business owner to ensure good communication and overall project success business owner steve yates title director of specialty products cch a wolters kluwer business phone email steve yates wolterskluwer com project manager steve hebert title sr manager of it applications development statement of work mps cch incorporated page of cch a wolters kluwer business phone email steve hebert wolterskluwer com client agrees with the scope of consultant s assigned duties as outlined in this sow and any deviation or additional services requested by client will not be covered by this agreement without the execution of a change order signatures this sow will be performed in accordance with the msa between consultant and client for and on behalf of mindtree limited by name title date for and on behalf of cch incorporated by name sam high title vice president cch incorporated date statement of work mps cch incorporated page of attachment system requirements workstation system requirements pentium or higher bit platform using amd x or intel em t technology operating system for all new hardware acquired of the units will run the latest version of microsoft vista business and of the units will run the latest version of microsoft vista ultimate gb ram minimum gb ram recommended latest version of mdac latest version of net framework latest version of microsoft internet explorer latest version of adobe reader minimum monitor screen resolution is x '"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.loc[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msa_regex_lookup(x):    \n",
    "    nonmsa_keywords = ['sow', 'statement of work', 'addendum', 'amendment', 'confidentiality agreement', 'disclosure agreement']\n",
    "    match1 = re.search(r\"(agreement agreement|master agreement|master services agreement|this agreement)\\s+(\\S+\\s+){1,30}(by and between|by and among|between|among)(.+?) and (.+?)\", x.text)\n",
    "    match2 = re.search(r\"(agreement agreement|master agreement|master services agreement|this agreement)\\s+(\\S+\\s+){1,30}(effective)(.+?) and (.+?)\", x.text)\n",
    "    match3 = re.search(r\"(agreement agreement|master agreement|master services agreement|this agreement)\\s+(\\S+\\s+){1,30}(the undersigned)(.+?) and (.+?)\", x.text)\n",
    "        \n",
    "    if (match1 and not(any(key in x.text[:match1.end()] for key in nonmsa_keywords))) \\\n",
    "        or (match2 and not(any(key in x.text[:match2.end()] for key in nonmsa_keywords))) \\\n",
    "        or (match3 and not(any(key in x.text[:match3.end()] for key in nonmsa_keywords))):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def addendum_regex_lookup(x):\n",
    "    match1 = re.search(r\"(addendum|amendment|change request|change order)\\s+(\\S+\\s+){1,30}(by and between|by and among|between) (.+?) and (.+?)\", x.text)\n",
    "    match2 = re.search(r\"(addendum|amendment)\\s+(\\S+\\s+){1,30}(schedule a|effective) (.+?) and (.+?)\", x.text)\n",
    "    match3 = re.search(r\"(addendum|amendment) (.+?) (the undersigned) (.+?) and (.+?)\", x.text)\n",
    "    \n",
    "    if (match1 and match1.start() < 1000) or (match2 and match2.start() < 1000) or (match3 and match3.start() < 1000):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def sow_regex_lookup(x):    \n",
    "    nonsow_keywords = ['addendum','amendment']\n",
    "    match1 = re.search(r\"(sow|statement of work|work order|task order)\\s+(\\S+\\s+){1,30}(by and between|by and among|executed by|between|entered into)(.+?) and (.+?)\", x.text)\n",
    "    match2 = re.search(r\"(sow|statement of work|work order|task order)\\s+(\\S+\\s+){1,30}(effective) (.+?) and (.+?)\", x.text)\n",
    "    match3 = re.search(r\"(sow|statement of work|work order|task order)\\s+(\\S+\\s+){1,30}(the undersigned) (.+?) and (.+?)\", x.text)\n",
    "       \n",
    "    if (match1 and match1.start() < 1000 and not(any(key in x.text[:match1.end()] for key in nonsow_keywords)) \\\n",
    "        or (match2 and match2.start() < 1000 and not(any(key not in x.text[:match2.end()] for key in nonsow_keywords))) \\\n",
    "        or match3 and match3.start() < 1000 and not(any(key not in x.text[:match3.end()] for key in nonsow_keywords))):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def nda_regex_lookup(x):\n",
    "    nda_keywords = ['mutual confidentiality', 'confidentiality agreement', 'disclosure agreement']\n",
    "    match1 = re.search(r\"(disclosure agreement|confidentiality agreement)\\s+(\\S+\\s+){1,30}(by and between|by and among|between|among)(.+?) and (.+?)\", x.text)\n",
    "    \n",
    "    if match1 and match1.start() < 1000 and any(key in x.text for key in nda_keywords):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def others_lookup(x):\n",
    "    msa = msa_regex_lookup(x)\n",
    "    sow = sow_regex_lookup(x)\n",
    "    addendum = addendum_regex_lookup(x)\n",
    "    nda = nda_regex_lookup(x)\n",
    "    \n",
    "    if msa == 0 and sow == 0 and addendum == 0 and nda == 0:\n",
    "        return 1\n",
    "    return 0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_keywords = ['indemnified party', 'indemnifying party', 'force majeure', 'industrial property right', 'privacy restricted data', \n",
    "                'prior written notice', 'subject matter hereof']\n",
    "\n",
    "addendum_keywords = ['addendum number', 'addendum date', 'addendum effective date',\n",
    "                     'term of addendum', 'term of amendment', 'addendum made',\n",
    "                     'addendum entered', 'duration of the addendum', 'purpose of the addendum', \n",
    "                     'subsequent addendum', 'amendment number', 'amendment date', 'amendment entered', \n",
    "                     'amendment made', 'amendment executed', 'amendment effective date', \n",
    "                     'agreement hereby amended', 'service agreement amendment']\n",
    "\n",
    "sow_keywords = ['sow effective date', 'work sow', 'sow shall', 'sow term', 'client sow', \n",
    "                'sow agreement', 'statement of work effective', 'sow end date', 'sow duration']\n",
    "\n",
    "nda_keywords = ['mutual confidentiality', 'affiliated entity', 'agreement negotiation', 'disclosure hereunder', \n",
    "                'mutual confidentiality agreement', 'non confidential basis', 'confidential information agent', \n",
    "                'confidentiality non disclosure', 'party certain confidential information',\n",
    "                'party furnish']\n",
    "\n",
    "other_keywords = ['sir madam', 'letter to inform', 'engagement letter', 'service order form',\n",
    "                  'change request form', 'signature form', 'agreement service order', 'service component order', \n",
    "                  'component order', 'editorial service order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unlabelled Dataset\n",
    "\n",
    "#Initialize empty dataframe\n",
    "df_latent_pred = pd.DataFrame()\n",
    "\n",
    "for index, row in df_pred.iterrows():    \n",
    "    msa_keywords_count = 0\n",
    "    sow_keywords_count = 0\n",
    "    nda_keywords_count = 0\n",
    "    addendum_keywords_count = 0\n",
    "    others_keywords_count = 0\n",
    "    \n",
    "    dict_latent = {}\n",
    "    dict_latent['DocID'] = row[\"filename\"]       \n",
    "           \n",
    "    #============MSA=============\n",
    "        \n",
    "    #Check for matching MSA keywords\n",
    "    for key in msa_keywords:\n",
    "        if key in row['text']:            \n",
    "            dict_latent[key] = 1             \n",
    "            msa_keywords_count += 1\n",
    "        else:\n",
    "            dict_latent[key] = 0\n",
    "    \n",
    "    dict_latent['msa_keywords_count'] = msa_keywords_count\n",
    "    \n",
    "    #Call MSA regex lookup function\n",
    "    dict_latent['msa_regex_lookup'] = msa_regex_lookup(row)\n",
    "                \n",
    "    #============SOW=============\n",
    "            \n",
    "    #Check for matching SOW keywords\n",
    "    for key in sow_keywords:\n",
    "        if key in row['text']:            \n",
    "            dict_latent[key] = 1\n",
    "            sow_keywords_count += 1\n",
    "        else:\n",
    "            dict_latent[key] = 0\n",
    "    \n",
    "    dict_latent['sow_keywords_count'] = sow_keywords_count\n",
    "    \n",
    "    #Call SOW regex lookup function\n",
    "    dict_latent['sow_regex_lookup'] = sow_regex_lookup(row)\n",
    "                \n",
    "    #==========ADDENDUM=============\n",
    "            \n",
    "    #Check for matching Addnedum keywords\n",
    "    for key in addendum_keywords:\n",
    "        if key in row['text']:            \n",
    "            dict_latent[key] = 1\n",
    "            addendum_keywords_count += 1\n",
    "        else:\n",
    "            dict_latent[key] = 0\n",
    "    \n",
    "    dict_latent['addendum_keywords_count'] = addendum_keywords_count\n",
    "        \n",
    "    #Call Addendum regex lookup function\n",
    "    dict_latent['addendum_regex_lookup'] = addendum_regex_lookup(row)        \n",
    "                \n",
    "    #============NDA=============\n",
    "        \n",
    "    #Check for matching NDA keywords\n",
    "    for key in nda_keywords:\n",
    "        if key in row['text']:            \n",
    "            dict_latent[key] = 1\n",
    "            nda_keywords_count += 1\n",
    "        else:\n",
    "            dict_latent[key] = 0\n",
    "    \n",
    "    dict_latent['nda_keywords_count'] = nda_keywords_count\n",
    "    \n",
    "    #Call NDA regex lookup function\n",
    "    dict_latent['nda_regex_lookup'] = nda_regex_lookup(row)\n",
    "    \n",
    "    #============Others===========\n",
    "    \n",
    "    #Check for matching Others keywords\n",
    "    for key in other_keywords:\n",
    "        if key in row['text']:            \n",
    "            dict_latent[key] = 1\n",
    "            others_keywords_count += 1\n",
    "        else:\n",
    "            dict_latent[key] = 0\n",
    "\n",
    "    dict_latent['others_keywords_count'] = others_keywords_count\n",
    "    \n",
    "    #Call Others regex lookup function\n",
    "    dict_latent['others_lookup'] = others_lookup(row)                \n",
    "    #break\n",
    "    \n",
    "    #Append dictionary to the DataFrame\n",
    "    df_latent_pred = df_latent_pred.append(dict_latent, ignore_index = True)    \n",
    "\n",
    "#fill NaNs with 0\n",
    "df_latent_pred.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DocID</th>\n",
       "      <th>addendum date</th>\n",
       "      <th>addendum effective date</th>\n",
       "      <th>addendum entered</th>\n",
       "      <th>addendum made</th>\n",
       "      <th>addendum number</th>\n",
       "      <th>addendum_keywords_count</th>\n",
       "      <th>addendum_regex_lookup</th>\n",
       "      <th>affiliated entity</th>\n",
       "      <th>agreement hereby amended</th>\n",
       "      <th>...</th>\n",
       "      <th>sow shall</th>\n",
       "      <th>sow term</th>\n",
       "      <th>sow_keywords_count</th>\n",
       "      <th>sow_regex_lookup</th>\n",
       "      <th>statement of work effective</th>\n",
       "      <th>subject matter hereof</th>\n",
       "      <th>subsequent addendum</th>\n",
       "      <th>term of addendum</th>\n",
       "      <th>term of amendment</th>\n",
       "      <th>work sow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>D00738.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D00862.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>D03070.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>D04125.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>D03866.txt</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DocID  addendum date  addendum effective date  addendum entered  \\\n",
       "0  D00738.txt            0.0                      0.0               0.0   \n",
       "1  D00862.txt            0.0                      0.0               0.0   \n",
       "2  D03070.txt            0.0                      0.0               0.0   \n",
       "3  D04125.txt            0.0                      0.0               0.0   \n",
       "4  D03866.txt            0.0                      0.0               0.0   \n",
       "\n",
       "   addendum made  addendum number  addendum_keywords_count  \\\n",
       "0            0.0              0.0                      1.0   \n",
       "1            0.0              0.0                      0.0   \n",
       "2            0.0              0.0                      0.0   \n",
       "3            0.0              0.0                      0.0   \n",
       "4            0.0              0.0                      0.0   \n",
       "\n",
       "   addendum_regex_lookup  affiliated entity  agreement hereby amended  ...  \\\n",
       "0                    1.0                0.0                       0.0  ...   \n",
       "1                    0.0                0.0                       0.0  ...   \n",
       "2                    0.0                0.0                       0.0  ...   \n",
       "3                    0.0                0.0                       0.0  ...   \n",
       "4                    0.0                0.0                       0.0  ...   \n",
       "\n",
       "   sow shall  sow term  sow_keywords_count  sow_regex_lookup  \\\n",
       "0        0.0       0.0                 0.0               0.0   \n",
       "1        1.0       0.0                 3.0               1.0   \n",
       "2        0.0       0.0                 0.0               0.0   \n",
       "3        0.0       0.0                 0.0               0.0   \n",
       "4        1.0       0.0                 3.0               1.0   \n",
       "\n",
       "   statement of work effective  subject matter hereof  subsequent addendum  \\\n",
       "0                          0.0                    0.0                  1.0   \n",
       "1                          0.0                    0.0                  0.0   \n",
       "2                          0.0                    1.0                  0.0   \n",
       "3                          0.0                    1.0                  0.0   \n",
       "4                          0.0                    0.0                  0.0   \n",
       "\n",
       "   term of addendum  term of amendment  work sow  \n",
       "0               0.0                0.0       0.0  \n",
       "1               0.0                0.0       1.0  \n",
       "2               0.0                0.0       0.0  \n",
       "3               0.0                0.0       0.0  \n",
       "4               0.0                0.0       1.0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_latent_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_latent_pred = df_latent_pred.drop(['DocID'], axis=1)\n",
    "df_latent_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.feature_extraction.text import CountVectorizer\\n\\n#Count Vectorizer\\nvectorizer = CountVectorizer(ngram_range=(1, 3), max_features=512)\\nx_train = vectorizer.fit_transform(df_train_filtered)\\nx_pred = vectorizer.transform(df_pred.text.tolist())'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#Count Vectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 3), max_features=512)\n",
    "x_train = vectorizer.fit_transform(df_train_filtered)\n",
    "x_pred = vectorizer.transform(df_pred.text.tolist())\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "countvect_model_pkl = '/home/user/Shyam/Code/Release_6.0/Dev/Snorkel/DCNN/models/count_vectorizer.pkl'\n",
    "with open(countvect_model_pkl, 'rb') as f:\n",
    "    countvect_model = pickle.load(f)\n",
    "\n",
    "x_pred = countvect_model.transform(df_pred.text.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 512)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 512\n",
    "latent_features_size = df_latent_pred.shape[1]\n",
    "word_index = 386003\n",
    "EMBEDDING_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.engine import Layer, InputSpec\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Embedding, Conv1D, Activation, ZeroPadding1D, Permute, Reshape, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "class KMaxPooling(Layer):\n",
    "    \"\"\"\n",
    "    K-max pooling layer that extracts the k-highest activations from a sequence (2nd dimension).\n",
    "    TensorFlow backend.\n",
    "    \"\"\"\n",
    "    def __init__(self, k=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_spec = InputSpec(ndim=3)\n",
    "        self.k = k\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], (input_shape[1] * self.k))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        # swap last two dimensions since top_k will be applied along the last dimension\n",
    "        #shifted_input = tf.transpose(inputs, [0, 2, 1])\n",
    "        \n",
    "        # extract top_k, returns two tensors [values, indices]\n",
    "        top_k = tf.nn.top_k(inputs, k=self.k, sorted=True, name=None)[0]\n",
    "        \n",
    "        # return flattened output\n",
    "        return top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two kinds of k's and kernel sizes for each operation\n",
    "def two_conv_dynamic_cnn(k1 = 12, k2 = 8, ksize1 = 5, ksize2 = 5):\n",
    "    inputs = Input(shape=(max_features,))\n",
    "    inputs_latent = Input(shape=(latent_features_size,))\n",
    "    embed = Embedding(word_index, 128, input_length=512)(inputs)\n",
    "    conv_results = []\n",
    "    # two feature maps using for loop\n",
    "    for i in range(2):\n",
    "        padded = ZeroPadding1D(ksize1 - 1)(embed)\n",
    "        conv1 = Conv1D(EMBEDDING_DIM, ksize1, activation = 'relu')(padded)\n",
    "        permuted = Permute((2,1))(conv1)\n",
    "        kmaxpool1 = KMaxPooling(k1)(permuted)\n",
    "        kmaxpool1 = Reshape((k1, -1))(kmaxpool1)\n",
    "        padded = ZeroPadding1D(ksize2 -1)(kmaxpool1)\n",
    "        conv2 = Conv1D(EMBEDDING_DIM, ksize2, activation = 'relu')(padded)\n",
    "        permuted = Permute((2,1))(conv2)\n",
    "        kmaxpool2 = KMaxPooling(k2)(permuted)\n",
    "        kmaxpool2 = Reshape((k2, -1))(kmaxpool2)\n",
    "        flattened = Flatten()(kmaxpool2)\n",
    "        conv_results.append(flattened)\n",
    "    x = concatenate(conv_results)\n",
    "    x = concatenate([x, inputs_latent], axis=1)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    outputs = Dense(5, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs = [inputs, inputs_latent], outputs = outputs)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_5 (InputLayer)             (None, 512)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)          (None, 512, 128)      49408384    input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding1d_9 (ZeroPadding1D) (None, 520, 128)      0           embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding1d_11 (ZeroPadding1D (None, 520, 128)      0           embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)                (None, 516, 128)      82048       zero_padding1d_9[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)               (None, 516, 128)      82048       zero_padding1d_11[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "permute_9 (Permute)              (None, 128, 516)      0           conv1d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "permute_11 (Permute)             (None, 128, 516)      0           conv1d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "k_max_pooling_9 (KMaxPooling)    (None, 1536)          0           permute_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "k_max_pooling_11 (KMaxPooling)   (None, 1536)          0           permute_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "reshape_9 (Reshape)              (None, 12, 128)       0           k_max_pooling_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "reshape_11 (Reshape)             (None, 12, 128)       0           k_max_pooling_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding1d_10 (ZeroPadding1D (None, 20, 128)       0           reshape_9[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "zero_padding1d_12 (ZeroPadding1D (None, 20, 128)       0           reshape_11[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)               (None, 16, 128)       82048       zero_padding1d_10[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)               (None, 16, 128)       82048       zero_padding1d_12[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "permute_10 (Permute)             (None, 128, 16)       0           conv1d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "permute_12 (Permute)             (None, 128, 16)       0           conv1d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "k_max_pooling_10 (KMaxPooling)   (None, 1024)          0           permute_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "k_max_pooling_12 (KMaxPooling)   (None, 1024)          0           permute_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "reshape_10 (Reshape)             (None, 8, 128)        0           k_max_pooling_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "reshape_12 (Reshape)             (None, 8, 128)        0           k_max_pooling_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)              (None, 1024)          0           reshape_10[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)              (None, 1024)          0           reshape_12[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)      (None, 2048)          0           flatten_5[0][0]                  \n",
      "                                                                   flatten_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "input_6 (InputLayer)             (None, 64)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)      (None, 2112)          0           concatenate_5[0][0]              \n",
      "                                                                   input_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 2112)          8448        concatenate_6[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 128)           270464      batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 128)           0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 5)             645         dropout_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 50,016,133\n",
      "Trainable params: 50,011,909\n",
      "Non-trainable params: 4,224\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "two_conv_dynamic_cnn = two_conv_dynamic_cnn()\n",
    "two_conv_dynamic_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_conv_dynamic_cnn.load_weights('/home/user/Shyam/Code/Release_6.0/Dev/Snorkel/DCNN/models/dcnn-10epochs-90.0-98.97-99.52.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\\n            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31],\\n           dtype='int64')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-82f41996ca37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprobs_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwo_conv_dynamic_cnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_latent_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1711\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[0;32m-> 1713\u001b[0;31m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[1;32m   1714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1264\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mins\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m                     \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_slice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2984\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2986\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 \u001b[0;31m# When setting, missing keys are not allowed, even with .loc:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"raise_missing\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_setter\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1092\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m         )\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 raise KeyError(\n\u001b[1;32m   1176\u001b[0m                     \"None of [{key}] are in the [{axis}]\".format(\n\u001b[0;32m-> 1177\u001b[0;31m                         \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m                     )\n\u001b[1;32m   1179\u001b[0m                 )\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\\n            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31],\\n           dtype='int64')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "probs_test = two_conv_dynamic_cnn.predict([x_pred, df_latent_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24063, 5)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['prediction'] = pd.Series(probs_test.argmax(axis=1)).map({0: 'Addendum', 1: 'MSA', 4: 'SOW', 2: 'NDA', 3: 'Others'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>D10357.txt</td>\n",
       "      <td>mrted service order form this order can be fa...</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D17119.txt</td>\n",
       "      <td>e book conversion prices usd vendor name exhi...</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>D33712.txt</td>\n",
       "      <td>statement of work ot between cch and blueswitc...</td>\n",
       "      <td>SOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>D40414.txt</td>\n",
       "      <td>addendum to agreement re managed services for ...</td>\n",
       "      <td>Addendum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>D42859.txt</td>\n",
       "      <td>agreement this independent contractor agreemen...</td>\n",
       "      <td>MSA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename                                               text prediction\n",
       "0  D10357.txt   mrted service order form this order can be fa...     Others\n",
       "1  D17119.txt   e book conversion prices usd vendor name exhi...     Others\n",
       "2  D33712.txt  statement of work ot between cch and blueswitc...        SOW\n",
       "3  D40414.txt  addendum to agreement re managed services for ...   Addendum\n",
       "4  D42859.txt  agreement this independent contractor agreemen...        MSA"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Others      12589\n",
       "MSA          5266\n",
       "Addendum     2411\n",
       "SOW          2388\n",
       "NDA          1409\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred.prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.to_csv('corpus_predictions.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
